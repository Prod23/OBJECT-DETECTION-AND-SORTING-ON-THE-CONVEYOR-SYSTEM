{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conveyor Object Detection - Data Analysis & Error Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis of the dataset and model performance for the conveyor object detection system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import yaml\n",
    "import json\n",
    "from collections import Counter\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "from src.data.dataset import DatasetManager\n",
    "from src.utils.visualization import DataAnalysisVisualizer, MetricsVisualizer\n",
    "from src.models.yolo_model import YOLOModelManager\n",
    "from ultralytics import YOLO\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset manager and analyze\n",
    "dataset_manager = DatasetManager()\n",
    "dataset_yaml_path = \"../data/processed/yolo_dataset/dataset.yaml\"\n",
    "\n",
    "try:\n",
    "    with open(dataset_yaml_path, 'r') as f:\n",
    "        dataset_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"Dataset Configuration:\")\n",
    "    print(f\"  Path: {dataset_config['path']}\")\n",
    "    print(f\"  Classes: {dataset_config['names']}\")\n",
    "    print(f\"  Number of classes: {dataset_config['nc']}\")\n",
    "    \n",
    "    analysis = dataset_manager.analyze_dataset(dataset_yaml_path)\n",
    "    \n",
    "    print(\"\\nDataset Analysis Summary:\")\n",
    "    for split, stats in analysis['splits'].items():\n",
    "        print(f\"  {split.upper()} Split:\")\n",
    "        print(f\"    Images: {stats['num_images']}\")\n",
    "        print(f\"    Labels: {stats['num_labels']}\")\n",
    "        print(f\"    Total Objects: {stats['total_objects']}\")\n",
    "        print(f\"    Objects per Image: {stats['total_objects']/stats['num_images']:.2f}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Dataset file not found: {dataset_yaml_path}\")\n",
    "    print(\"Please run the data preparation script first.\")\n",
    "    analysis = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis:\n",
    "    class_dist = analysis['class_distribution']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    classes = list(class_dist.keys())\n",
    "    counts = list(class_dist.values())\n",
    "    \n",
    "    bars = axes[0].bar(classes, counts, color=['skyblue', 'lightcoral'])\n",
    "    axes[0].set_title('Overall Class Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Classes')\n",
    "    axes[0].set_ylabel('Number of Instances')\n",
    "    \n",
    "    for bar, count in zip(bars, counts):\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01,\n",
    "                    str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    axes[1].pie(counts, labels=classes, autopct='%1.1f%%', startangle=90,\n",
    "               colors=['skyblue', 'lightcoral'])\n",
    "    axes[1].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    total_objects = sum(counts)\n",
    "    imbalance_ratio = max(counts) / min(counts) if min(counts) > 0 else float('inf')\n",
    "    \n",
    "    print(f\"\\nClass Imbalance Analysis:\")\n",
    "    print(f\"  Total objects: {total_objects}\")\n",
    "    print(f\"  Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "    \n",
    "    if imbalance_ratio > 2:\n",
    "        print(\"  ‚ö†Ô∏è  Significant class imbalance detected!\")\n",
    "        print(\"  Consider using class weights or data augmentation.\")\n",
    "    else:\n",
    "        print(\"  ‚úÖ Classes are relatively balanced.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for training results\n",
    "results_dir = Path(\"../runs/train\")\n",
    "metrics_files = list(results_dir.glob(\"**/results.csv\")) if results_dir.exists() else []\n",
    "\n",
    "if metrics_files:\n",
    "    latest_results = max(metrics_files, key=lambda x: x.stat().st_mtime)\n",
    "    print(f\"Loading training results from: {latest_results}\")\n",
    "    \n",
    "    try:\n",
    "        metrics_df = pd.read_csv(latest_results)\n",
    "        metrics_df.columns = metrics_df.columns.str.strip()\n",
    "        \n",
    "        print(f\"\\nTraining completed after {len(metrics_df)} epochs\")\n",
    "        \n",
    "        final_metrics = metrics_df.iloc[-1]\n",
    "        print(\"\\nüìà Final Training Metrics:\")\n",
    "        \n",
    "        metric_names = {\n",
    "            'metrics/precision(B)': 'Precision',\n",
    "            'metrics/recall(B)': 'Recall',\n",
    "            'metrics/mAP50(B)': 'mAP@0.5',\n",
    "            'metrics/mAP50-95(B)': 'mAP@0.5:0.95'\n",
    "        }\n",
    "        \n",
    "        for col, name in metric_names.items():\n",
    "            if col in final_metrics:\n",
    "                print(f\"  {name}: {final_metrics[col]:.4f}\")\n",
    "        \n",
    "        # Plot training curves\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Training Metrics Over Time', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        if 'train/box_loss' in metrics_df.columns and 'val/box_loss' in metrics_df.columns:\n",
    "            axes[0, 0].plot(metrics_df['epoch'], metrics_df['train/box_loss'], 'b-', label='Train')\n",
    "            axes[0, 0].plot(metrics_df['epoch'], metrics_df['val/box_loss'], 'r-', label='Validation')\n",
    "            axes[0, 0].set_title('Box Loss')\n",
    "            axes[0, 0].legend()\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        if 'metrics/precision(B)' in metrics_df.columns and 'metrics/recall(B)' in metrics_df.columns:\n",
    "            axes[0, 1].plot(metrics_df['epoch'], metrics_df['metrics/precision(B)'], 'g-', label='Precision')\n",
    "            axes[0, 1].plot(metrics_df['epoch'], metrics_df['metrics/recall(B)'], 'orange', label='Recall')\n",
    "            axes[0, 1].set_title('Precision & Recall')\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        if 'metrics/mAP50(B)' in metrics_df.columns:\n",
    "            axes[1, 0].plot(metrics_df['epoch'], metrics_df['metrics/mAP50(B)'], 'purple', label='mAP@0.5')\n",
    "            axes[1, 0].set_title('mAP@0.5')\n",
    "            axes[1, 0].legend()\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        if 'lr/pg0' in metrics_df.columns:\n",
    "            axes[1, 1].plot(metrics_df['epoch'], metrics_df['lr/pg0'], 'red')\n",
    "            axes[1, 1].set_title('Learning Rate')\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading metrics: {e}\")\n",
    "else:\n",
    "    print(\"No training results found. Train a model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Error Analysis and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Error Analysis and Recommendations:\")\n",
    "print(\"\\n1. Data Quality:\")\n",
    "if analysis:\n",
    "    total_images = sum(stats['num_images'] for stats in analysis['splits'].values())\n",
    "    total_objects = sum(analysis['class_distribution'].values())\n",
    "    print(f\"   ‚Ä¢ Dataset size: {total_images} images, {total_objects} objects\")\n",
    "    print(f\"   ‚Ä¢ Average objects per image: {total_objects/total_images:.2f}\")\n",
    "    \n",
    "    if total_images < 1000:\n",
    "        print(\"   ‚ö†Ô∏è  Small dataset - consider collecting more data\")\n",
    "    elif total_images < 5000:\n",
    "        print(\"   ‚úÖ Moderate dataset size - good for initial training\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Large dataset - excellent for robust training\")\n",
    "\n",
    "print(\"\\n2. Model Performance:\")\n",
    "print(\"   ‚Ä¢ Monitor validation loss to detect overfitting\")\n",
    "print(\"   ‚Ä¢ Target mAP@0.5 > 0.8 for production deployment\")\n",
    "print(\"   ‚Ä¢ Precision > 0.9 important for conveyor sorting accuracy\")\n",
    "\n",
    "print(\"\\n3. Conveyor-Specific Considerations:\")\n",
    "print(\"   ‚Ä¢ Test with different lighting conditions\")\n",
    "print(\"   ‚Ä¢ Validate performance at different belt speeds\")\n",
    "print(\"   ‚Ä¢ Consider object occlusion scenarios\")\n",
    "print(\"   ‚Ä¢ Test with worn/damaged objects\")\n",
    "\n",
    "print(\"\\n4. Deployment Recommendations:\")\n",
    "print(\"   ‚Ä¢ Export to ONNX for faster inference\")\n",
    "print(\"   ‚Ä¢ Implement confidence thresholding (>0.7 recommended)\")\n",
    "print(\"   ‚Ä¢ Add object tracking for temporal consistency\")\n",
    "print(\"   ‚Ä¢ Monitor inference FPS (target >30 FPS)\")\n",
    "\n",
    "print(\"\\n5. Next Steps:\")\n",
    "print(\"   ‚Ä¢ Collect edge case data (poor lighting, damaged objects)\")\n",
    "print(\"   ‚Ä¢ Implement A/B testing for model versions\")\n",
    "print(\"   ‚Ä¢ Set up continuous monitoring in production\")\n",
    "print(\"   ‚Ä¢ Create feedback loop for model improvement\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
